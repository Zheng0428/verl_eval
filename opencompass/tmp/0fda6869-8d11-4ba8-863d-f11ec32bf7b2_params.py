datasets = [
    [
        dict(
            abbr='lukaemon_mmlu_college_biology_3',
            eval_cfg=dict(
                evaluator=dict(
                    type='opencompass.openicl.icl_evaluator.AccEvaluator'),
                pred_postprocessor=dict(
                    options='ABCD',
                    type=
                    'opencompass.utils.text_postprocessors.first_option_postprocess'
                )),
            infer_cfg=dict(
                ice_template=dict(
                    template=dict(round=[
                        dict(
                            prompt=
                            'There is a single choice question about college biology. Answer the question by replying A, B, C or D.\nQ: {input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nA: ',
                            role='HUMAN'),
                        dict(prompt='{target}\n', role='BOT'),
                    ]),
                    type=
                    'opencompass.openicl.icl_prompt_template.PromptTemplate'),
                inferencer=dict(
                    max_out_len=8192,
                    type='opencompass.openicl.icl_inferencer.GenInferencer'),
                prompt_template=dict(
                    ice_token='</E>',
                    template=dict(
                        begin='</E>',
                        round=[
                            dict(
                                prompt=
                                "Question:\nThere is a single choice question about college biology. Answer the question by replying A, B, C or D. {input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer:\nLet's think step by step.\n",
                                role='HUMAN'),
                        ]),
                    type=
                    'opencompass.openicl.icl_prompt_template.PromptTemplate'),
                retriever=dict(
                    type='opencompass.openicl.icl_retriever.ZeroRetriever')),
            name='college_biology',
            path='opencompass/mmlu',
            reader_cfg=dict(
                input_columns=[
                    'input',
                    'A',
                    'B',
                    'C',
                    'D',
                ],
                output_column='target',
                test_range='[87:116]',
                train_split='dev'),
            type='opencompass.datasets.MMLUDataset'),
        dict(
            abbr='lukaemon_mmlu_college_chemistry_3',
            eval_cfg=dict(
                evaluator=dict(
                    type='opencompass.openicl.icl_evaluator.AccEvaluator'),
                pred_postprocessor=dict(
                    options='ABCD',
                    type=
                    'opencompass.utils.text_postprocessors.first_option_postprocess'
                )),
            infer_cfg=dict(
                ice_template=dict(
                    template=dict(round=[
                        dict(
                            prompt=
                            'There is a single choice question about college chemistry. Answer the question by replying A, B, C or D.\nQ: {input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nA: ',
                            role='HUMAN'),
                        dict(prompt='{target}\n', role='BOT'),
                    ]),
                    type=
                    'opencompass.openicl.icl_prompt_template.PromptTemplate'),
                inferencer=dict(
                    max_out_len=8192,
                    type='opencompass.openicl.icl_inferencer.GenInferencer'),
                prompt_template=dict(
                    ice_token='</E>',
                    template=dict(
                        begin='</E>',
                        round=[
                            dict(
                                prompt=
                                "Question:\nThere is a single choice question about college chemistry. Answer the question by replying A, B, C or D. {input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer:\nLet's think step by step.\n",
                                role='HUMAN'),
                        ]),
                    type=
                    'opencompass.openicl.icl_prompt_template.PromptTemplate'),
                retriever=dict(
                    type='opencompass.openicl.icl_retriever.ZeroRetriever')),
            name='college_chemistry',
            path='opencompass/mmlu',
            reader_cfg=dict(
                input_columns=[
                    'input',
                    'A',
                    'B',
                    'C',
                    'D',
                ],
                output_column='target',
                test_range='[60:80]',
                train_split='dev'),
            type='opencompass.datasets.MMLUDataset'),
        dict(
            abbr='lukaemon_mmlu_college_computer_science_3',
            eval_cfg=dict(
                evaluator=dict(
                    type='opencompass.openicl.icl_evaluator.AccEvaluator'),
                pred_postprocessor=dict(
                    options='ABCD',
                    type=
                    'opencompass.utils.text_postprocessors.first_option_postprocess'
                )),
            infer_cfg=dict(
                ice_template=dict(
                    template=dict(round=[
                        dict(
                            prompt=
                            'There is a single choice question about college computer science. Answer the question by replying A, B, C or D.\nQ: {input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nA: ',
                            role='HUMAN'),
                        dict(prompt='{target}\n', role='BOT'),
                    ]),
                    type=
                    'opencompass.openicl.icl_prompt_template.PromptTemplate'),
                inferencer=dict(
                    max_out_len=8192,
                    type='opencompass.openicl.icl_inferencer.GenInferencer'),
                prompt_template=dict(
                    ice_token='</E>',
                    template=dict(
                        begin='</E>',
                        round=[
                            dict(
                                prompt=
                                "Question:\nThere is a single choice question about college computer science. Answer the question by replying A, B, C or D. {input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer:\nLet's think step by step.\n",
                                role='HUMAN'),
                        ]),
                    type=
                    'opencompass.openicl.icl_prompt_template.PromptTemplate'),
                retriever=dict(
                    type='opencompass.openicl.icl_retriever.ZeroRetriever')),
            name='college_computer_science',
            path='opencompass/mmlu',
            reader_cfg=dict(
                input_columns=[
                    'input',
                    'A',
                    'B',
                    'C',
                    'D',
                ],
                output_column='target',
                test_range='[60:80]',
                train_split='dev'),
            type='opencompass.datasets.MMLUDataset'),
        dict(
            abbr='lukaemon_mmlu_college_mathematics_3',
            eval_cfg=dict(
                evaluator=dict(
                    type='opencompass.openicl.icl_evaluator.AccEvaluator'),
                pred_postprocessor=dict(
                    options='ABCD',
                    type=
                    'opencompass.utils.text_postprocessors.first_option_postprocess'
                )),
            infer_cfg=dict(
                ice_template=dict(
                    template=dict(round=[
                        dict(
                            prompt=
                            'There is a single choice question about college mathematics. Answer the question by replying A, B, C or D.\nQ: {input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nA: ',
                            role='HUMAN'),
                        dict(prompt='{target}\n', role='BOT'),
                    ]),
                    type=
                    'opencompass.openicl.icl_prompt_template.PromptTemplate'),
                inferencer=dict(
                    max_out_len=8192,
                    type='opencompass.openicl.icl_inferencer.GenInferencer'),
                prompt_template=dict(
                    ice_token='</E>',
                    template=dict(
                        begin='</E>',
                        round=[
                            dict(
                                prompt=
                                "Question:\nThere is a single choice question about college mathematics. Answer the question by replying A, B, C or D. {input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer:\nLet's think step by step.\n",
                                role='HUMAN'),
                        ]),
                    type=
                    'opencompass.openicl.icl_prompt_template.PromptTemplate'),
                retriever=dict(
                    type='opencompass.openicl.icl_retriever.ZeroRetriever')),
            name='college_mathematics',
            path='opencompass/mmlu',
            reader_cfg=dict(
                input_columns=[
                    'input',
                    'A',
                    'B',
                    'C',
                    'D',
                ],
                output_column='target',
                test_range='[60:80]',
                train_split='dev'),
            type='opencompass.datasets.MMLUDataset'),
        dict(
            abbr='lukaemon_mmlu_college_physics_3',
            eval_cfg=dict(
                evaluator=dict(
                    type='opencompass.openicl.icl_evaluator.AccEvaluator'),
                pred_postprocessor=dict(
                    options='ABCD',
                    type=
                    'opencompass.utils.text_postprocessors.first_option_postprocess'
                )),
            infer_cfg=dict(
                ice_template=dict(
                    template=dict(round=[
                        dict(
                            prompt=
                            'There is a single choice question about college physics. Answer the question by replying A, B, C or D.\nQ: {input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nA: ',
                            role='HUMAN'),
                        dict(prompt='{target}\n', role='BOT'),
                    ]),
                    type=
                    'opencompass.openicl.icl_prompt_template.PromptTemplate'),
                inferencer=dict(
                    max_out_len=8192,
                    type='opencompass.openicl.icl_inferencer.GenInferencer'),
                prompt_template=dict(
                    ice_token='</E>',
                    template=dict(
                        begin='</E>',
                        round=[
                            dict(
                                prompt=
                                "Question:\nThere is a single choice question about college physics. Answer the question by replying A, B, C or D. {input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer:\nLet's think step by step.\n",
                                role='HUMAN'),
                        ]),
                    type=
                    'opencompass.openicl.icl_prompt_template.PromptTemplate'),
                retriever=dict(
                    type='opencompass.openicl.icl_retriever.ZeroRetriever')),
            name='college_physics',
            path='opencompass/mmlu',
            reader_cfg=dict(
                input_columns=[
                    'input',
                    'A',
                    'B',
                    'C',
                    'D',
                ],
                output_column='target',
                test_range='[63:84]',
                train_split='dev'),
            type='opencompass.datasets.MMLUDataset'),
        dict(
            abbr='lukaemon_mmlu_electrical_engineering_3',
            eval_cfg=dict(
                evaluator=dict(
                    type='opencompass.openicl.icl_evaluator.AccEvaluator'),
                pred_postprocessor=dict(
                    options='ABCD',
                    type=
                    'opencompass.utils.text_postprocessors.first_option_postprocess'
                )),
            infer_cfg=dict(
                ice_template=dict(
                    template=dict(round=[
                        dict(
                            prompt=
                            'There is a single choice question about electrical engineering. Answer the question by replying A, B, C or D.\nQ: {input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nA: ',
                            role='HUMAN'),
                        dict(prompt='{target}\n', role='BOT'),
                    ]),
                    type=
                    'opencompass.openicl.icl_prompt_template.PromptTemplate'),
                inferencer=dict(
                    max_out_len=8192,
                    type='opencompass.openicl.icl_inferencer.GenInferencer'),
                prompt_template=dict(
                    ice_token='</E>',
                    template=dict(
                        begin='</E>',
                        round=[
                            dict(
                                prompt=
                                "Question:\nThere is a single choice question about electrical engineering. Answer the question by replying A, B, C or D. {input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer:\nLet's think step by step.\n",
                                role='HUMAN'),
                        ]),
                    type=
                    'opencompass.openicl.icl_prompt_template.PromptTemplate'),
                retriever=dict(
                    type='opencompass.openicl.icl_retriever.ZeroRetriever')),
            name='electrical_engineering',
            path='opencompass/mmlu',
            reader_cfg=dict(
                input_columns=[
                    'input',
                    'A',
                    'B',
                    'C',
                    'D',
                ],
                output_column='target',
                test_range='[87:116]',
                train_split='dev'),
            type='opencompass.datasets.MMLUDataset'),
        dict(
            abbr='lukaemon_mmlu_astronomy_3',
            eval_cfg=dict(
                evaluator=dict(
                    type='opencompass.openicl.icl_evaluator.AccEvaluator'),
                pred_postprocessor=dict(
                    options='ABCD',
                    type=
                    'opencompass.utils.text_postprocessors.first_option_postprocess'
                )),
            infer_cfg=dict(
                ice_template=dict(
                    template=dict(round=[
                        dict(
                            prompt=
                            'There is a single choice question about astronomy. Answer the question by replying A, B, C or D.\nQ: {input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nA: ',
                            role='HUMAN'),
                        dict(prompt='{target}\n', role='BOT'),
                    ]),
                    type=
                    'opencompass.openicl.icl_prompt_template.PromptTemplate'),
                inferencer=dict(
                    max_out_len=8192,
                    type='opencompass.openicl.icl_inferencer.GenInferencer'),
                prompt_template=dict(
                    ice_token='</E>',
                    template=dict(
                        begin='</E>',
                        round=[
                            dict(
                                prompt=
                                "Question:\nThere is a single choice question about astronomy. Answer the question by replying A, B, C or D. {input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer:\nLet's think step by step.\n",
                                role='HUMAN'),
                        ]),
                    type=
                    'opencompass.openicl.icl_prompt_template.PromptTemplate'),
                retriever=dict(
                    type='opencompass.openicl.icl_retriever.ZeroRetriever')),
            name='astronomy',
            path='opencompass/mmlu',
            reader_cfg=dict(
                input_columns=[
                    'input',
                    'A',
                    'B',
                    'C',
                    'D',
                ],
                output_column='target',
                test_range='[93:124]',
                train_split='dev'),
            type='opencompass.datasets.MMLUDataset'),
        dict(
            abbr='lukaemon_mmlu_anatomy_3',
            eval_cfg=dict(
                evaluator=dict(
                    type='opencompass.openicl.icl_evaluator.AccEvaluator'),
                pred_postprocessor=dict(
                    options='ABCD',
                    type=
                    'opencompass.utils.text_postprocessors.first_option_postprocess'
                )),
            infer_cfg=dict(
                ice_template=dict(
                    template=dict(round=[
                        dict(
                            prompt=
                            'There is a single choice question about anatomy. Answer the question by replying A, B, C or D.\nQ: {input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nA: ',
                            role='HUMAN'),
                        dict(prompt='{target}\n', role='BOT'),
                    ]),
                    type=
                    'opencompass.openicl.icl_prompt_template.PromptTemplate'),
                inferencer=dict(
                    max_out_len=8192,
                    type='opencompass.openicl.icl_inferencer.GenInferencer'),
                prompt_template=dict(
                    ice_token='</E>',
                    template=dict(
                        begin='</E>',
                        round=[
                            dict(
                                prompt=
                                "Question:\nThere is a single choice question about anatomy. Answer the question by replying A, B, C or D. {input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer:\nLet's think step by step.\n",
                                role='HUMAN'),
                        ]),
                    type=
                    'opencompass.openicl.icl_prompt_template.PromptTemplate'),
                retriever=dict(
                    type='opencompass.openicl.icl_retriever.ZeroRetriever')),
            name='anatomy',
            path='opencompass/mmlu',
            reader_cfg=dict(
                input_columns=[
                    'input',
                    'A',
                    'B',
                    'C',
                    'D',
                ],
                output_column='target',
                test_range='[81:108]',
                train_split='dev'),
            type='opencompass.datasets.MMLUDataset'),
        dict(
            abbr='lukaemon_mmlu_abstract_algebra_3',
            eval_cfg=dict(
                evaluator=dict(
                    type='opencompass.openicl.icl_evaluator.AccEvaluator'),
                pred_postprocessor=dict(
                    options='ABCD',
                    type=
                    'opencompass.utils.text_postprocessors.first_option_postprocess'
                )),
            infer_cfg=dict(
                ice_template=dict(
                    template=dict(round=[
                        dict(
                            prompt=
                            'There is a single choice question about abstract algebra. Answer the question by replying A, B, C or D.\nQ: {input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nA: ',
                            role='HUMAN'),
                        dict(prompt='{target}\n', role='BOT'),
                    ]),
                    type=
                    'opencompass.openicl.icl_prompt_template.PromptTemplate'),
                inferencer=dict(
                    max_out_len=8192,
                    type='opencompass.openicl.icl_inferencer.GenInferencer'),
                prompt_template=dict(
                    ice_token='</E>',
                    template=dict(
                        begin='</E>',
                        round=[
                            dict(
                                prompt=
                                "Question:\nThere is a single choice question about abstract algebra. Answer the question by replying A, B, C or D. {input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer:\nLet's think step by step.\n",
                                role='HUMAN'),
                        ]),
                    type=
                    'opencompass.openicl.icl_prompt_template.PromptTemplate'),
                retriever=dict(
                    type='opencompass.openicl.icl_retriever.ZeroRetriever')),
            name='abstract_algebra',
            path='opencompass/mmlu',
            reader_cfg=dict(
                input_columns=[
                    'input',
                    'A',
                    'B',
                    'C',
                    'D',
                ],
                output_column='target',
                test_range='[60:80]',
                train_split='dev'),
            type='opencompass.datasets.MMLUDataset'),
        dict(
            abbr='lukaemon_mmlu_machine_learning_3',
            eval_cfg=dict(
                evaluator=dict(
                    type='opencompass.openicl.icl_evaluator.AccEvaluator'),
                pred_postprocessor=dict(
                    options='ABCD',
                    type=
                    'opencompass.utils.text_postprocessors.first_option_postprocess'
                )),
            infer_cfg=dict(
                ice_template=dict(
                    template=dict(round=[
                        dict(
                            prompt=
                            'There is a single choice question about machine learning. Answer the question by replying A, B, C or D.\nQ: {input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nA: ',
                            role='HUMAN'),
                        dict(prompt='{target}\n', role='BOT'),
                    ]),
                    type=
                    'opencompass.openicl.icl_prompt_template.PromptTemplate'),
                inferencer=dict(
                    max_out_len=8192,
                    type='opencompass.openicl.icl_inferencer.GenInferencer'),
                prompt_template=dict(
                    ice_token='</E>',
                    template=dict(
                        begin='</E>',
                        round=[
                            dict(
                                prompt=
                                "Question:\nThere is a single choice question about machine learning. Answer the question by replying A, B, C or D. {input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer:\nLet's think step by step.\n",
                                role='HUMAN'),
                        ]),
                    type=
                    'opencompass.openicl.icl_prompt_template.PromptTemplate'),
                retriever=dict(
                    type='opencompass.openicl.icl_retriever.ZeroRetriever')),
            name='machine_learning',
            path='opencompass/mmlu',
            reader_cfg=dict(
                input_columns=[
                    'input',
                    'A',
                    'B',
                    'C',
                    'D',
                ],
                output_column='target',
                test_range='[69:92]',
                train_split='dev'),
            type='opencompass.datasets.MMLUDataset'),
        dict(
            abbr='lukaemon_mmlu_clinical_knowledge_3',
            eval_cfg=dict(
                evaluator=dict(
                    type='opencompass.openicl.icl_evaluator.AccEvaluator'),
                pred_postprocessor=dict(
                    options='ABCD',
                    type=
                    'opencompass.utils.text_postprocessors.first_option_postprocess'
                )),
            infer_cfg=dict(
                ice_template=dict(
                    template=dict(round=[
                        dict(
                            prompt=
                            'There is a single choice question about clinical knowledge. Answer the question by replying A, B, C or D.\nQ: {input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nA: ',
                            role='HUMAN'),
                        dict(prompt='{target}\n', role='BOT'),
                    ]),
                    type=
                    'opencompass.openicl.icl_prompt_template.PromptTemplate'),
                inferencer=dict(
                    max_out_len=8192,
                    type='opencompass.openicl.icl_inferencer.GenInferencer'),
                prompt_template=dict(
                    ice_token='</E>',
                    template=dict(
                        begin='</E>',
                        round=[
                            dict(
                                prompt=
                                "Question:\nThere is a single choice question about clinical knowledge. Answer the question by replying A, B, C or D. {input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer:\nLet's think step by step.\n",
                                role='HUMAN'),
                        ]),
                    type=
                    'opencompass.openicl.icl_prompt_template.PromptTemplate'),
                retriever=dict(
                    type='opencompass.openicl.icl_retriever.ZeroRetriever')),
            name='clinical_knowledge',
            path='opencompass/mmlu',
            reader_cfg=dict(
                input_columns=[
                    'input',
                    'A',
                    'B',
                    'C',
                    'D',
                ],
                output_column='target',
                test_range='[159:212]',
                train_split='dev'),
            type='opencompass.datasets.MMLUDataset'),
        dict(
            abbr='lukaemon_mmlu_global_facts_3',
            eval_cfg=dict(
                evaluator=dict(
                    type='opencompass.openicl.icl_evaluator.AccEvaluator'),
                pred_postprocessor=dict(
                    options='ABCD',
                    type=
                    'opencompass.utils.text_postprocessors.first_option_postprocess'
                )),
            infer_cfg=dict(
                ice_template=dict(
                    template=dict(round=[
                        dict(
                            prompt=
                            'There is a single choice question about global facts. Answer the question by replying A, B, C or D.\nQ: {input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nA: ',
                            role='HUMAN'),
                        dict(prompt='{target}\n', role='BOT'),
                    ]),
                    type=
                    'opencompass.openicl.icl_prompt_template.PromptTemplate'),
                inferencer=dict(
                    max_out_len=8192,
                    type='opencompass.openicl.icl_inferencer.GenInferencer'),
                prompt_template=dict(
                    ice_token='</E>',
                    template=dict(
                        begin='</E>',
                        round=[
                            dict(
                                prompt=
                                "Question:\nThere is a single choice question about global facts. Answer the question by replying A, B, C or D. {input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer:\nLet's think step by step.\n",
                                role='HUMAN'),
                        ]),
                    type=
                    'opencompass.openicl.icl_prompt_template.PromptTemplate'),
                retriever=dict(
                    type='opencompass.openicl.icl_retriever.ZeroRetriever')),
            name='global_facts',
            path='opencompass/mmlu',
            reader_cfg=dict(
                input_columns=[
                    'input',
                    'A',
                    'B',
                    'C',
                    'D',
                ],
                output_column='target',
                test_range='[60:80]',
                train_split='dev'),
            type='opencompass.datasets.MMLUDataset'),
        dict(
            abbr='lukaemon_mmlu_management_3',
            eval_cfg=dict(
                evaluator=dict(
                    type='opencompass.openicl.icl_evaluator.AccEvaluator'),
                pred_postprocessor=dict(
                    options='ABCD',
                    type=
                    'opencompass.utils.text_postprocessors.first_option_postprocess'
                )),
            infer_cfg=dict(
                ice_template=dict(
                    template=dict(round=[
                        dict(
                            prompt=
                            'There is a single choice question about management. Answer the question by replying A, B, C or D.\nQ: {input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nA: ',
                            role='HUMAN'),
                        dict(prompt='{target}\n', role='BOT'),
                    ]),
                    type=
                    'opencompass.openicl.icl_prompt_template.PromptTemplate'),
                inferencer=dict(
                    max_out_len=8192,
                    type='opencompass.openicl.icl_inferencer.GenInferencer'),
                prompt_template=dict(
                    ice_token='</E>',
                    template=dict(
                        begin='</E>',
                        round=[
                            dict(
                                prompt=
                                "Question:\nThere is a single choice question about management. Answer the question by replying A, B, C or D. {input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer:\nLet's think step by step.\n",
                                role='HUMAN'),
                        ]),
                    type=
                    'opencompass.openicl.icl_prompt_template.PromptTemplate'),
                retriever=dict(
                    type='opencompass.openicl.icl_retriever.ZeroRetriever')),
            name='management',
            path='opencompass/mmlu',
            reader_cfg=dict(
                input_columns=[
                    'input',
                    'A',
                    'B',
                    'C',
                    'D',
                ],
                output_column='target',
                test_range='[63:84]',
                train_split='dev'),
            type='opencompass.datasets.MMLUDataset'),
        dict(
            abbr='lukaemon_mmlu_nutrition_3',
            eval_cfg=dict(
                evaluator=dict(
                    type='opencompass.openicl.icl_evaluator.AccEvaluator'),
                pred_postprocessor=dict(
                    options='ABCD',
                    type=
                    'opencompass.utils.text_postprocessors.first_option_postprocess'
                )),
            infer_cfg=dict(
                ice_template=dict(
                    template=dict(round=[
                        dict(
                            prompt=
                            'There is a single choice question about nutrition. Answer the question by replying A, B, C or D.\nQ: {input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nA: ',
                            role='HUMAN'),
                        dict(prompt='{target}\n', role='BOT'),
                    ]),
                    type=
                    'opencompass.openicl.icl_prompt_template.PromptTemplate'),
                inferencer=dict(
                    max_out_len=8192,
                    type='opencompass.openicl.icl_inferencer.GenInferencer'),
                prompt_template=dict(
                    ice_token='</E>',
                    template=dict(
                        begin='</E>',
                        round=[
                            dict(
                                prompt=
                                "Question:\nThere is a single choice question about nutrition. Answer the question by replying A, B, C or D. {input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer:\nLet's think step by step.\n",
                                role='HUMAN'),
                        ]),
                    type=
                    'opencompass.openicl.icl_prompt_template.PromptTemplate'),
                retriever=dict(
                    type='opencompass.openicl.icl_retriever.ZeroRetriever')),
            name='nutrition',
            path='opencompass/mmlu',
            reader_cfg=dict(
                input_columns=[
                    'input',
                    'A',
                    'B',
                    'C',
                    'D',
                ],
                output_column='target',
                test_range='[186:248]',
                train_split='dev'),
            type='opencompass.datasets.MMLUDataset'),
        dict(
            abbr='lukaemon_mmlu_marketing_3',
            eval_cfg=dict(
                evaluator=dict(
                    type='opencompass.openicl.icl_evaluator.AccEvaluator'),
                pred_postprocessor=dict(
                    options='ABCD',
                    type=
                    'opencompass.utils.text_postprocessors.first_option_postprocess'
                )),
            infer_cfg=dict(
                ice_template=dict(
                    template=dict(round=[
                        dict(
                            prompt=
                            'There is a single choice question about marketing. Answer the question by replying A, B, C or D.\nQ: {input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nA: ',
                            role='HUMAN'),
                        dict(prompt='{target}\n', role='BOT'),
                    ]),
                    type=
                    'opencompass.openicl.icl_prompt_template.PromptTemplate'),
                inferencer=dict(
                    max_out_len=8192,
                    type='opencompass.openicl.icl_inferencer.GenInferencer'),
                prompt_template=dict(
                    ice_token='</E>',
                    template=dict(
                        begin='</E>',
                        round=[
                            dict(
                                prompt=
                                "Question:\nThere is a single choice question about marketing. Answer the question by replying A, B, C or D. {input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer:\nLet's think step by step.\n",
                                role='HUMAN'),
                        ]),
                    type=
                    'opencompass.openicl.icl_prompt_template.PromptTemplate'),
                retriever=dict(
                    type='opencompass.openicl.icl_retriever.ZeroRetriever')),
            name='marketing',
            path='opencompass/mmlu',
            reader_cfg=dict(
                input_columns=[
                    'input',
                    'A',
                    'B',
                    'C',
                    'D',
                ],
                output_column='target',
                test_range='[141:188]',
                train_split='dev'),
            type='opencompass.datasets.MMLUDataset'),
        dict(
            abbr='lukaemon_mmlu_professional_accounting_3',
            eval_cfg=dict(
                evaluator=dict(
                    type='opencompass.openicl.icl_evaluator.AccEvaluator'),
                pred_postprocessor=dict(
                    options='ABCD',
                    type=
                    'opencompass.utils.text_postprocessors.first_option_postprocess'
                )),
            infer_cfg=dict(
                ice_template=dict(
                    template=dict(round=[
                        dict(
                            prompt=
                            'There is a single choice question about professional accounting. Answer the question by replying A, B, C or D.\nQ: {input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nA: ',
                            role='HUMAN'),
                        dict(prompt='{target}\n', role='BOT'),
                    ]),
                    type=
                    'opencompass.openicl.icl_prompt_template.PromptTemplate'),
                inferencer=dict(
                    max_out_len=8192,
                    type='opencompass.openicl.icl_inferencer.GenInferencer'),
                prompt_template=dict(
                    ice_token='</E>',
                    template=dict(
                        begin='</E>',
                        round=[
                            dict(
                                prompt=
                                "Question:\nThere is a single choice question about professional accounting. Answer the question by replying A, B, C or D. {input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer:\nLet's think step by step.\n",
                                role='HUMAN'),
                        ]),
                    type=
                    'opencompass.openicl.icl_prompt_template.PromptTemplate'),
                retriever=dict(
                    type='opencompass.openicl.icl_retriever.ZeroRetriever')),
            name='professional_accounting',
            path='opencompass/mmlu',
            reader_cfg=dict(
                input_columns=[
                    'input',
                    'A',
                    'B',
                    'C',
                    'D',
                ],
                output_column='target',
                test_range='[171:228]',
                train_split='dev'),
            type='opencompass.datasets.MMLUDataset'),
        dict(
            abbr='lukaemon_mmlu_high_school_geography_3',
            eval_cfg=dict(
                evaluator=dict(
                    type='opencompass.openicl.icl_evaluator.AccEvaluator'),
                pred_postprocessor=dict(
                    options='ABCD',
                    type=
                    'opencompass.utils.text_postprocessors.first_option_postprocess'
                )),
            infer_cfg=dict(
                ice_template=dict(
                    template=dict(round=[
                        dict(
                            prompt=
                            'There is a single choice question about high school geography. Answer the question by replying A, B, C or D.\nQ: {input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nA: ',
                            role='HUMAN'),
                        dict(prompt='{target}\n', role='BOT'),
                    ]),
                    type=
                    'opencompass.openicl.icl_prompt_template.PromptTemplate'),
                inferencer=dict(
                    max_out_len=8192,
                    type='opencompass.openicl.icl_inferencer.GenInferencer'),
                prompt_template=dict(
                    ice_token='</E>',
                    template=dict(
                        begin='</E>',
                        round=[
                            dict(
                                prompt=
                                "Question:\nThere is a single choice question about high school geography. Answer the question by replying A, B, C or D. {input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer:\nLet's think step by step.\n",
                                role='HUMAN'),
                        ]),
                    type=
                    'opencompass.openicl.icl_prompt_template.PromptTemplate'),
                retriever=dict(
                    type='opencompass.openicl.icl_retriever.ZeroRetriever')),
            name='high_school_geography',
            path='opencompass/mmlu',
            reader_cfg=dict(
                input_columns=[
                    'input',
                    'A',
                    'B',
                    'C',
                    'D',
                ],
                output_column='target',
                test_range='[120:160]',
                train_split='dev'),
            type='opencompass.datasets.MMLUDataset'),
        dict(
            abbr='lukaemon_mmlu_international_law_3',
            eval_cfg=dict(
                evaluator=dict(
                    type='opencompass.openicl.icl_evaluator.AccEvaluator'),
                pred_postprocessor=dict(
                    options='ABCD',
                    type=
                    'opencompass.utils.text_postprocessors.first_option_postprocess'
                )),
            infer_cfg=dict(
                ice_template=dict(
                    template=dict(round=[
                        dict(
                            prompt=
                            'There is a single choice question about international law. Answer the question by replying A, B, C or D.\nQ: {input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nA: ',
                            role='HUMAN'),
                        dict(prompt='{target}\n', role='BOT'),
                    ]),
                    type=
                    'opencompass.openicl.icl_prompt_template.PromptTemplate'),
                inferencer=dict(
                    max_out_len=8192,
                    type='opencompass.openicl.icl_inferencer.GenInferencer'),
                prompt_template=dict(
                    ice_token='</E>',
                    template=dict(
                        begin='</E>',
                        round=[
                            dict(
                                prompt=
                                "Question:\nThere is a single choice question about international law. Answer the question by replying A, B, C or D. {input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer:\nLet's think step by step.\n",
                                role='HUMAN'),
                        ]),
                    type=
                    'opencompass.openicl.icl_prompt_template.PromptTemplate'),
                retriever=dict(
                    type='opencompass.openicl.icl_retriever.ZeroRetriever')),
            name='international_law',
            path='opencompass/mmlu',
            reader_cfg=dict(
                input_columns=[
                    'input',
                    'A',
                    'B',
                    'C',
                    'D',
                ],
                output_column='target',
                test_range='[75:100]',
                train_split='dev'),
            type='opencompass.datasets.MMLUDataset'),
        dict(
            abbr='lukaemon_mmlu_moral_scenarios_3',
            eval_cfg=dict(
                evaluator=dict(
                    type='opencompass.openicl.icl_evaluator.AccEvaluator'),
                pred_postprocessor=dict(
                    options='ABCD',
                    type=
                    'opencompass.utils.text_postprocessors.first_option_postprocess'
                )),
            infer_cfg=dict(
                ice_template=dict(
                    template=dict(round=[
                        dict(
                            prompt=
                            'There is a single choice question about moral scenarios. Answer the question by replying A, B, C or D.\nQ: {input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nA: ',
                            role='HUMAN'),
                        dict(prompt='{target}\n', role='BOT'),
                    ]),
                    type=
                    'opencompass.openicl.icl_prompt_template.PromptTemplate'),
                inferencer=dict(
                    max_out_len=8192,
                    type='opencompass.openicl.icl_inferencer.GenInferencer'),
                prompt_template=dict(
                    ice_token='</E>',
                    template=dict(
                        begin='</E>',
                        round=[
                            dict(
                                prompt=
                                "Question:\nThere is a single choice question about moral scenarios. Answer the question by replying A, B, C or D. {input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer:\nLet's think step by step.\n",
                                role='HUMAN'),
                        ]),
                    type=
                    'opencompass.openicl.icl_prompt_template.PromptTemplate'),
                retriever=dict(
                    type='opencompass.openicl.icl_retriever.ZeroRetriever')),
            name='moral_scenarios',
            path='opencompass/mmlu',
            reader_cfg=dict(
                input_columns=[
                    'input',
                    'A',
                    'B',
                    'C',
                    'D',
                ],
                output_column='target',
                test_range='[537:716]',
                train_split='dev'),
            type='opencompass.datasets.MMLUDataset'),
        dict(
            abbr='lukaemon_mmlu_computer_security_3',
            eval_cfg=dict(
                evaluator=dict(
                    type='opencompass.openicl.icl_evaluator.AccEvaluator'),
                pred_postprocessor=dict(
                    options='ABCD',
                    type=
                    'opencompass.utils.text_postprocessors.first_option_postprocess'
                )),
            infer_cfg=dict(
                ice_template=dict(
                    template=dict(round=[
                        dict(
                            prompt=
                            'There is a single choice question about computer security. Answer the question by replying A, B, C or D.\nQ: {input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nA: ',
                            role='HUMAN'),
                        dict(prompt='{target}\n', role='BOT'),
                    ]),
                    type=
                    'opencompass.openicl.icl_prompt_template.PromptTemplate'),
                inferencer=dict(
                    max_out_len=8192,
                    type='opencompass.openicl.icl_inferencer.GenInferencer'),
                prompt_template=dict(
                    ice_token='</E>',
                    template=dict(
                        begin='</E>',
                        round=[
                            dict(
                                prompt=
                                "Question:\nThere is a single choice question about computer security. Answer the question by replying A, B, C or D. {input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer:\nLet's think step by step.\n",
                                role='HUMAN'),
                        ]),
                    type=
                    'opencompass.openicl.icl_prompt_template.PromptTemplate'),
                retriever=dict(
                    type='opencompass.openicl.icl_retriever.ZeroRetriever')),
            name='computer_security',
            path='opencompass/mmlu',
            reader_cfg=dict(
                input_columns=[
                    'input',
                    'A',
                    'B',
                    'C',
                    'D',
                ],
                output_column='target',
                test_range='[60:80]',
                train_split='dev'),
            type='opencompass.datasets.MMLUDataset'),
        dict(
            abbr='lukaemon_mmlu_high_school_microeconomics_3',
            eval_cfg=dict(
                evaluator=dict(
                    type='opencompass.openicl.icl_evaluator.AccEvaluator'),
                pred_postprocessor=dict(
                    options='ABCD',
                    type=
                    'opencompass.utils.text_postprocessors.first_option_postprocess'
                )),
            infer_cfg=dict(
                ice_template=dict(
                    template=dict(round=[
                        dict(
                            prompt=
                            'There is a single choice question about high school microeconomics. Answer the question by replying A, B, C or D.\nQ: {input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nA: ',
                            role='HUMAN'),
                        dict(prompt='{target}\n', role='BOT'),
                    ]),
                    type=
                    'opencompass.openicl.icl_prompt_template.PromptTemplate'),
                inferencer=dict(
                    max_out_len=8192,
                    type='opencompass.openicl.icl_inferencer.GenInferencer'),
                prompt_template=dict(
                    ice_token='</E>',
                    template=dict(
                        begin='</E>',
                        round=[
                            dict(
                                prompt=
                                "Question:\nThere is a single choice question about high school microeconomics. Answer the question by replying A, B, C or D. {input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer:\nLet's think step by step.\n",
                                role='HUMAN'),
                        ]),
                    type=
                    'opencompass.openicl.icl_prompt_template.PromptTemplate'),
                retriever=dict(
                    type='opencompass.openicl.icl_retriever.ZeroRetriever')),
            name='high_school_microeconomics',
            path='opencompass/mmlu',
            reader_cfg=dict(
                input_columns=[
                    'input',
                    'A',
                    'B',
                    'C',
                    'D',
                ],
                output_column='target',
                test_range='[144:192]',
                train_split='dev'),
            type='opencompass.datasets.MMLUDataset'),
        dict(
            abbr='lukaemon_mmlu_professional_law_3',
            eval_cfg=dict(
                evaluator=dict(
                    type='opencompass.openicl.icl_evaluator.AccEvaluator'),
                pred_postprocessor=dict(
                    options='ABCD',
                    type=
                    'opencompass.utils.text_postprocessors.first_option_postprocess'
                )),
            infer_cfg=dict(
                ice_template=dict(
                    template=dict(round=[
                        dict(
                            prompt=
                            'There is a single choice question about professional law. Answer the question by replying A, B, C or D.\nQ: {input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nA: ',
                            role='HUMAN'),
                        dict(prompt='{target}\n', role='BOT'),
                    ]),
                    type=
                    'opencompass.openicl.icl_prompt_template.PromptTemplate'),
                inferencer=dict(
                    max_out_len=8192,
                    type='opencompass.openicl.icl_inferencer.GenInferencer'),
                prompt_template=dict(
                    ice_token='</E>',
                    template=dict(
                        begin='</E>',
                        round=[
                            dict(
                                prompt=
                                "Question:\nThere is a single choice question about professional law. Answer the question by replying A, B, C or D. {input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer:\nLet's think step by step.\n",
                                role='HUMAN'),
                        ]),
                    type=
                    'opencompass.openicl.icl_prompt_template.PromptTemplate'),
                retriever=dict(
                    type='opencompass.openicl.icl_retriever.ZeroRetriever')),
            name='professional_law',
            path='opencompass/mmlu',
            reader_cfg=dict(
                input_columns=[
                    'input',
                    'A',
                    'B',
                    'C',
                    'D',
                ],
                output_column='target',
                test_range='[921:1228]',
                train_split='dev'),
            type='opencompass.datasets.MMLUDataset'),
        dict(
            abbr='lukaemon_mmlu_medical_genetics_3',
            eval_cfg=dict(
                evaluator=dict(
                    type='opencompass.openicl.icl_evaluator.AccEvaluator'),
                pred_postprocessor=dict(
                    options='ABCD',
                    type=
                    'opencompass.utils.text_postprocessors.first_option_postprocess'
                )),
            infer_cfg=dict(
                ice_template=dict(
                    template=dict(round=[
                        dict(
                            prompt=
                            'There is a single choice question about medical genetics. Answer the question by replying A, B, C or D.\nQ: {input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nA: ',
                            role='HUMAN'),
                        dict(prompt='{target}\n', role='BOT'),
                    ]),
                    type=
                    'opencompass.openicl.icl_prompt_template.PromptTemplate'),
                inferencer=dict(
                    max_out_len=8192,
                    type='opencompass.openicl.icl_inferencer.GenInferencer'),
                prompt_template=dict(
                    ice_token='</E>',
                    template=dict(
                        begin='</E>',
                        round=[
                            dict(
                                prompt=
                                "Question:\nThere is a single choice question about medical genetics. Answer the question by replying A, B, C or D. {input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer:\nLet's think step by step.\n",
                                role='HUMAN'),
                        ]),
                    type=
                    'opencompass.openicl.icl_prompt_template.PromptTemplate'),
                retriever=dict(
                    type='opencompass.openicl.icl_retriever.ZeroRetriever')),
            name='medical_genetics',
            path='opencompass/mmlu',
            reader_cfg=dict(
                input_columns=[
                    'input',
                    'A',
                    'B',
                    'C',
                    'D',
                ],
                output_column='target',
                test_range='[60:80]',
                train_split='dev'),
            type='opencompass.datasets.MMLUDataset'),
        dict(
            abbr='lukaemon_mmlu_professional_psychology_3',
            eval_cfg=dict(
                evaluator=dict(
                    type='opencompass.openicl.icl_evaluator.AccEvaluator'),
                pred_postprocessor=dict(
                    options='ABCD',
                    type=
                    'opencompass.utils.text_postprocessors.first_option_postprocess'
                )),
            infer_cfg=dict(
                ice_template=dict(
                    template=dict(round=[
                        dict(
                            prompt=
                            'There is a single choice question about professional psychology. Answer the question by replying A, B, C or D.\nQ: {input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nA: ',
                            role='HUMAN'),
                        dict(prompt='{target}\n', role='BOT'),
                    ]),
                    type=
                    'opencompass.openicl.icl_prompt_template.PromptTemplate'),
                inferencer=dict(
                    max_out_len=8192,
                    type='opencompass.openicl.icl_inferencer.GenInferencer'),
                prompt_template=dict(
                    ice_token='</E>',
                    template=dict(
                        begin='</E>',
                        round=[
                            dict(
                                prompt=
                                "Question:\nThere is a single choice question about professional psychology. Answer the question by replying A, B, C or D. {input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer:\nLet's think step by step.\n",
                                role='HUMAN'),
                        ]),
                    type=
                    'opencompass.openicl.icl_prompt_template.PromptTemplate'),
                retriever=dict(
                    type='opencompass.openicl.icl_retriever.ZeroRetriever')),
            name='professional_psychology',
            path='opencompass/mmlu',
            reader_cfg=dict(
                input_columns=[
                    'input',
                    'A',
                    'B',
                    'C',
                    'D',
                ],
                output_column='target',
                test_range='[369:492]',
                train_split='dev'),
            type='opencompass.datasets.MMLUDataset'),
        dict(
            abbr='lukaemon_mmlu_jurisprudence_3',
            eval_cfg=dict(
                evaluator=dict(
                    type='opencompass.openicl.icl_evaluator.AccEvaluator'),
                pred_postprocessor=dict(
                    options='ABCD',
                    type=
                    'opencompass.utils.text_postprocessors.first_option_postprocess'
                )),
            infer_cfg=dict(
                ice_template=dict(
                    template=dict(round=[
                        dict(
                            prompt=
                            'There is a single choice question about jurisprudence. Answer the question by replying A, B, C or D.\nQ: {input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nA: ',
                            role='HUMAN'),
                        dict(prompt='{target}\n', role='BOT'),
                    ]),
                    type=
                    'opencompass.openicl.icl_prompt_template.PromptTemplate'),
                inferencer=dict(
                    max_out_len=8192,
                    type='opencompass.openicl.icl_inferencer.GenInferencer'),
                prompt_template=dict(
                    ice_token='</E>',
                    template=dict(
                        begin='</E>',
                        round=[
                            dict(
                                prompt=
                                "Question:\nThere is a single choice question about jurisprudence. Answer the question by replying A, B, C or D. {input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer:\nLet's think step by step.\n",
                                role='HUMAN'),
                        ]),
                    type=
                    'opencompass.openicl.icl_prompt_template.PromptTemplate'),
                retriever=dict(
                    type='opencompass.openicl.icl_retriever.ZeroRetriever')),
            name='jurisprudence',
            path='opencompass/mmlu',
            reader_cfg=dict(
                input_columns=[
                    'input',
                    'A',
                    'B',
                    'C',
                    'D',
                ],
                output_column='target',
                test_range='[66:88]',
                train_split='dev'),
            type='opencompass.datasets.MMLUDataset'),
        dict(
            abbr='lukaemon_mmlu_world_religions_3',
            eval_cfg=dict(
                evaluator=dict(
                    type='opencompass.openicl.icl_evaluator.AccEvaluator'),
                pred_postprocessor=dict(
                    options='ABCD',
                    type=
                    'opencompass.utils.text_postprocessors.first_option_postprocess'
                )),
            infer_cfg=dict(
                ice_template=dict(
                    template=dict(round=[
                        dict(
                            prompt=
                            'There is a single choice question about world religions. Answer the question by replying A, B, C or D.\nQ: {input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nA: ',
                            role='HUMAN'),
                        dict(prompt='{target}\n', role='BOT'),
                    ]),
                    type=
                    'opencompass.openicl.icl_prompt_template.PromptTemplate'),
                inferencer=dict(
                    max_out_len=8192,
                    type='opencompass.openicl.icl_inferencer.GenInferencer'),
                prompt_template=dict(
                    ice_token='</E>',
                    template=dict(
                        begin='</E>',
                        round=[
                            dict(
                                prompt=
                                "Question:\nThere is a single choice question about world religions. Answer the question by replying A, B, C or D. {input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer:\nLet's think step by step.\n",
                                role='HUMAN'),
                        ]),
                    type=
                    'opencompass.openicl.icl_prompt_template.PromptTemplate'),
                retriever=dict(
                    type='opencompass.openicl.icl_retriever.ZeroRetriever')),
            name='world_religions',
            path='opencompass/mmlu',
            reader_cfg=dict(
                input_columns=[
                    'input',
                    'A',
                    'B',
                    'C',
                    'D',
                ],
                output_column='target',
                test_range='[105:140]',
                train_split='dev'),
            type='opencompass.datasets.MMLUDataset'),
        dict(
            abbr='lukaemon_mmlu_philosophy_3',
            eval_cfg=dict(
                evaluator=dict(
                    type='opencompass.openicl.icl_evaluator.AccEvaluator'),
                pred_postprocessor=dict(
                    options='ABCD',
                    type=
                    'opencompass.utils.text_postprocessors.first_option_postprocess'
                )),
            infer_cfg=dict(
                ice_template=dict(
                    template=dict(round=[
                        dict(
                            prompt=
                            'There is a single choice question about philosophy. Answer the question by replying A, B, C or D.\nQ: {input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nA: ',
                            role='HUMAN'),
                        dict(prompt='{target}\n', role='BOT'),
                    ]),
                    type=
                    'opencompass.openicl.icl_prompt_template.PromptTemplate'),
                inferencer=dict(
                    max_out_len=8192,
                    type='opencompass.openicl.icl_inferencer.GenInferencer'),
                prompt_template=dict(
                    ice_token='</E>',
                    template=dict(
                        begin='</E>',
                        round=[
                            dict(
                                prompt=
                                "Question:\nThere is a single choice question about philosophy. Answer the question by replying A, B, C or D. {input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer:\nLet's think step by step.\n",
                                role='HUMAN'),
                        ]),
                    type=
                    'opencompass.openicl.icl_prompt_template.PromptTemplate'),
                retriever=dict(
                    type='opencompass.openicl.icl_retriever.ZeroRetriever')),
            name='philosophy',
            path='opencompass/mmlu',
            reader_cfg=dict(
                input_columns=[
                    'input',
                    'A',
                    'B',
                    'C',
                    'D',
                ],
                output_column='target',
                test_range='[189:252]',
                train_split='dev'),
            type='opencompass.datasets.MMLUDataset'),
        dict(
            abbr='lukaemon_mmlu_virology_3',
            eval_cfg=dict(
                evaluator=dict(
                    type='opencompass.openicl.icl_evaluator.AccEvaluator'),
                pred_postprocessor=dict(
                    options='ABCD',
                    type=
                    'opencompass.utils.text_postprocessors.first_option_postprocess'
                )),
            infer_cfg=dict(
                ice_template=dict(
                    template=dict(round=[
                        dict(
                            prompt=
                            'There is a single choice question about virology. Answer the question by replying A, B, C or D.\nQ: {input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nA: ',
                            role='HUMAN'),
                        dict(prompt='{target}\n', role='BOT'),
                    ]),
                    type=
                    'opencompass.openicl.icl_prompt_template.PromptTemplate'),
                inferencer=dict(
                    max_out_len=8192,
                    type='opencompass.openicl.icl_inferencer.GenInferencer'),
                prompt_template=dict(
                    ice_token='</E>',
                    template=dict(
                        begin='</E>',
                        round=[
                            dict(
                                prompt=
                                "Question:\nThere is a single choice question about virology. Answer the question by replying A, B, C or D. {input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer:\nLet's think step by step.\n",
                                role='HUMAN'),
                        ]),
                    type=
                    'opencompass.openicl.icl_prompt_template.PromptTemplate'),
                retriever=dict(
                    type='opencompass.openicl.icl_retriever.ZeroRetriever')),
            name='virology',
            path='opencompass/mmlu',
            reader_cfg=dict(
                input_columns=[
                    'input',
                    'A',
                    'B',
                    'C',
                    'D',
                ],
                output_column='target',
                test_range='[102:136]',
                train_split='dev'),
            type='opencompass.datasets.MMLUDataset'),
        dict(
            abbr='lukaemon_mmlu_high_school_chemistry_3',
            eval_cfg=dict(
                evaluator=dict(
                    type='opencompass.openicl.icl_evaluator.AccEvaluator'),
                pred_postprocessor=dict(
                    options='ABCD',
                    type=
                    'opencompass.utils.text_postprocessors.first_option_postprocess'
                )),
            infer_cfg=dict(
                ice_template=dict(
                    template=dict(round=[
                        dict(
                            prompt=
                            'There is a single choice question about high school chemistry. Answer the question by replying A, B, C or D.\nQ: {input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nA: ',
                            role='HUMAN'),
                        dict(prompt='{target}\n', role='BOT'),
                    ]),
                    type=
                    'opencompass.openicl.icl_prompt_template.PromptTemplate'),
                inferencer=dict(
                    max_out_len=8192,
                    type='opencompass.openicl.icl_inferencer.GenInferencer'),
                prompt_template=dict(
                    ice_token='</E>',
                    template=dict(
                        begin='</E>',
                        round=[
                            dict(
                                prompt=
                                "Question:\nThere is a single choice question about high school chemistry. Answer the question by replying A, B, C or D. {input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer:\nLet's think step by step.\n",
                                role='HUMAN'),
                        ]),
                    type=
                    'opencompass.openicl.icl_prompt_template.PromptTemplate'),
                retriever=dict(
                    type='opencompass.openicl.icl_retriever.ZeroRetriever')),
            name='high_school_chemistry',
            path='opencompass/mmlu',
            reader_cfg=dict(
                input_columns=[
                    'input',
                    'A',
                    'B',
                    'C',
                    'D',
                ],
                output_column='target',
                test_range='[123:164]',
                train_split='dev'),
            type='opencompass.datasets.MMLUDataset'),
        dict(
            abbr='lukaemon_mmlu_public_relations_3',
            eval_cfg=dict(
                evaluator=dict(
                    type='opencompass.openicl.icl_evaluator.AccEvaluator'),
                pred_postprocessor=dict(
                    options='ABCD',
                    type=
                    'opencompass.utils.text_postprocessors.first_option_postprocess'
                )),
            infer_cfg=dict(
                ice_template=dict(
                    template=dict(round=[
                        dict(
                            prompt=
                            'There is a single choice question about public relations. Answer the question by replying A, B, C or D.\nQ: {input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nA: ',
                            role='HUMAN'),
                        dict(prompt='{target}\n', role='BOT'),
                    ]),
                    type=
                    'opencompass.openicl.icl_prompt_template.PromptTemplate'),
                inferencer=dict(
                    max_out_len=8192,
                    type='opencompass.openicl.icl_inferencer.GenInferencer'),
                prompt_template=dict(
                    ice_token='</E>',
                    template=dict(
                        begin='</E>',
                        round=[
                            dict(
                                prompt=
                                "Question:\nThere is a single choice question about public relations. Answer the question by replying A, B, C or D. {input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer:\nLet's think step by step.\n",
                                role='HUMAN'),
                        ]),
                    type=
                    'opencompass.openicl.icl_prompt_template.PromptTemplate'),
                retriever=dict(
                    type='opencompass.openicl.icl_retriever.ZeroRetriever')),
            name='public_relations',
            path='opencompass/mmlu',
            reader_cfg=dict(
                input_columns=[
                    'input',
                    'A',
                    'B',
                    'C',
                    'D',
                ],
                output_column='target',
                test_range='[66:88]',
                train_split='dev'),
            type='opencompass.datasets.MMLUDataset'),
        dict(
            abbr='lukaemon_mmlu_high_school_macroeconomics_3',
            eval_cfg=dict(
                evaluator=dict(
                    type='opencompass.openicl.icl_evaluator.AccEvaluator'),
                pred_postprocessor=dict(
                    options='ABCD',
                    type=
                    'opencompass.utils.text_postprocessors.first_option_postprocess'
                )),
            infer_cfg=dict(
                ice_template=dict(
                    template=dict(round=[
                        dict(
                            prompt=
                            'There is a single choice question about high school macroeconomics. Answer the question by replying A, B, C or D.\nQ: {input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nA: ',
                            role='HUMAN'),
                        dict(prompt='{target}\n', role='BOT'),
                    ]),
                    type=
                    'opencompass.openicl.icl_prompt_template.PromptTemplate'),
                inferencer=dict(
                    max_out_len=8192,
                    type='opencompass.openicl.icl_inferencer.GenInferencer'),
                prompt_template=dict(
                    ice_token='</E>',
                    template=dict(
                        begin='</E>',
                        round=[
                            dict(
                                prompt=
                                "Question:\nThere is a single choice question about high school macroeconomics. Answer the question by replying A, B, C or D. {input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer:\nLet's think step by step.\n",
                                role='HUMAN'),
                        ]),
                    type=
                    'opencompass.openicl.icl_prompt_template.PromptTemplate'),
                retriever=dict(
                    type='opencompass.openicl.icl_retriever.ZeroRetriever')),
            name='high_school_macroeconomics',
            path='opencompass/mmlu',
            reader_cfg=dict(
                input_columns=[
                    'input',
                    'A',
                    'B',
                    'C',
                    'D',
                ],
                output_column='target',
                test_range='[234:312]',
                train_split='dev'),
            type='opencompass.datasets.MMLUDataset'),
        dict(
            abbr='lukaemon_mmlu_human_sexuality_3',
            eval_cfg=dict(
                evaluator=dict(
                    type='opencompass.openicl.icl_evaluator.AccEvaluator'),
                pred_postprocessor=dict(
                    options='ABCD',
                    type=
                    'opencompass.utils.text_postprocessors.first_option_postprocess'
                )),
            infer_cfg=dict(
                ice_template=dict(
                    template=dict(round=[
                        dict(
                            prompt=
                            'There is a single choice question about human sexuality. Answer the question by replying A, B, C or D.\nQ: {input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nA: ',
                            role='HUMAN'),
                        dict(prompt='{target}\n', role='BOT'),
                    ]),
                    type=
                    'opencompass.openicl.icl_prompt_template.PromptTemplate'),
                inferencer=dict(
                    max_out_len=8192,
                    type='opencompass.openicl.icl_inferencer.GenInferencer'),
                prompt_template=dict(
                    ice_token='</E>',
                    template=dict(
                        begin='</E>',
                        round=[
                            dict(
                                prompt=
                                "Question:\nThere is a single choice question about human sexuality. Answer the question by replying A, B, C or D. {input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer:\nLet's think step by step.\n",
                                role='HUMAN'),
                        ]),
                    type=
                    'opencompass.openicl.icl_prompt_template.PromptTemplate'),
                retriever=dict(
                    type='opencompass.openicl.icl_retriever.ZeroRetriever')),
            name='human_sexuality',
            path='opencompass/mmlu',
            reader_cfg=dict(
                input_columns=[
                    'input',
                    'A',
                    'B',
                    'C',
                    'D',
                ],
                output_column='target',
                test_range='[81:108]',
                train_split='dev'),
            type='opencompass.datasets.MMLUDataset'),
        dict(
            abbr='lukaemon_mmlu_elementary_mathematics_3',
            eval_cfg=dict(
                evaluator=dict(
                    type='opencompass.openicl.icl_evaluator.AccEvaluator'),
                pred_postprocessor=dict(
                    options='ABCD',
                    type=
                    'opencompass.utils.text_postprocessors.first_option_postprocess'
                )),
            infer_cfg=dict(
                ice_template=dict(
                    template=dict(round=[
                        dict(
                            prompt=
                            'There is a single choice question about elementary mathematics. Answer the question by replying A, B, C or D.\nQ: {input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nA: ',
                            role='HUMAN'),
                        dict(prompt='{target}\n', role='BOT'),
                    ]),
                    type=
                    'opencompass.openicl.icl_prompt_template.PromptTemplate'),
                inferencer=dict(
                    max_out_len=8192,
                    type='opencompass.openicl.icl_inferencer.GenInferencer'),
                prompt_template=dict(
                    ice_token='</E>',
                    template=dict(
                        begin='</E>',
                        round=[
                            dict(
                                prompt=
                                "Question:\nThere is a single choice question about elementary mathematics. Answer the question by replying A, B, C or D. {input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer:\nLet's think step by step.\n",
                                role='HUMAN'),
                        ]),
                    type=
                    'opencompass.openicl.icl_prompt_template.PromptTemplate'),
                retriever=dict(
                    type='opencompass.openicl.icl_retriever.ZeroRetriever')),
            name='elementary_mathematics',
            path='opencompass/mmlu',
            reader_cfg=dict(
                input_columns=[
                    'input',
                    'A',
                    'B',
                    'C',
                    'D',
                ],
                output_column='target',
                test_range='[228:304]',
                train_split='dev'),
            type='opencompass.datasets.MMLUDataset'),
        dict(
            abbr='lukaemon_mmlu_high_school_physics_3',
            eval_cfg=dict(
                evaluator=dict(
                    type='opencompass.openicl.icl_evaluator.AccEvaluator'),
                pred_postprocessor=dict(
                    options='ABCD',
                    type=
                    'opencompass.utils.text_postprocessors.first_option_postprocess'
                )),
            infer_cfg=dict(
                ice_template=dict(
                    template=dict(round=[
                        dict(
                            prompt=
                            'There is a single choice question about high school physics. Answer the question by replying A, B, C or D.\nQ: {input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nA: ',
                            role='HUMAN'),
                        dict(prompt='{target}\n', role='BOT'),
                    ]),
                    type=
                    'opencompass.openicl.icl_prompt_template.PromptTemplate'),
                inferencer=dict(
                    max_out_len=8192,
                    type='opencompass.openicl.icl_inferencer.GenInferencer'),
                prompt_template=dict(
                    ice_token='</E>',
                    template=dict(
                        begin='</E>',
                        round=[
                            dict(
                                prompt=
                                "Question:\nThere is a single choice question about high school physics. Answer the question by replying A, B, C or D. {input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer:\nLet's think step by step.\n",
                                role='HUMAN'),
                        ]),
                    type=
                    'opencompass.openicl.icl_prompt_template.PromptTemplate'),
                retriever=dict(
                    type='opencompass.openicl.icl_retriever.ZeroRetriever')),
            name='high_school_physics',
            path='opencompass/mmlu',
            reader_cfg=dict(
                input_columns=[
                    'input',
                    'A',
                    'B',
                    'C',
                    'D',
                ],
                output_column='target',
                test_range='[93:124]',
                train_split='dev'),
            type='opencompass.datasets.MMLUDataset'),
        dict(
            abbr='lukaemon_mmlu_high_school_computer_science_3',
            eval_cfg=dict(
                evaluator=dict(
                    type='opencompass.openicl.icl_evaluator.AccEvaluator'),
                pred_postprocessor=dict(
                    options='ABCD',
                    type=
                    'opencompass.utils.text_postprocessors.first_option_postprocess'
                )),
            infer_cfg=dict(
                ice_template=dict(
                    template=dict(round=[
                        dict(
                            prompt=
                            'There is a single choice question about high school computer science. Answer the question by replying A, B, C or D.\nQ: {input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nA: ',
                            role='HUMAN'),
                        dict(prompt='{target}\n', role='BOT'),
                    ]),
                    type=
                    'opencompass.openicl.icl_prompt_template.PromptTemplate'),
                inferencer=dict(
                    max_out_len=8192,
                    type='opencompass.openicl.icl_inferencer.GenInferencer'),
                prompt_template=dict(
                    ice_token='</E>',
                    template=dict(
                        begin='</E>',
                        round=[
                            dict(
                                prompt=
                                "Question:\nThere is a single choice question about high school computer science. Answer the question by replying A, B, C or D. {input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer:\nLet's think step by step.\n",
                                role='HUMAN'),
                        ]),
                    type=
                    'opencompass.openicl.icl_prompt_template.PromptTemplate'),
                retriever=dict(
                    type='opencompass.openicl.icl_retriever.ZeroRetriever')),
            name='high_school_computer_science',
            path='opencompass/mmlu',
            reader_cfg=dict(
                input_columns=[
                    'input',
                    'A',
                    'B',
                    'C',
                    'D',
                ],
                output_column='target',
                test_range='[60:80]',
                train_split='dev'),
            type='opencompass.datasets.MMLUDataset'),
        dict(
            abbr='lukaemon_mmlu_high_school_european_history_3',
            eval_cfg=dict(
                evaluator=dict(
                    type='opencompass.openicl.icl_evaluator.AccEvaluator'),
                pred_postprocessor=dict(
                    options='ABCD',
                    type=
                    'opencompass.utils.text_postprocessors.first_option_postprocess'
                )),
            infer_cfg=dict(
                ice_template=dict(
                    template=dict(round=[
                        dict(
                            prompt=
                            'There is a single choice question about high school european history. Answer the question by replying A, B, C or D.\nQ: {input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nA: ',
                            role='HUMAN'),
                        dict(prompt='{target}\n', role='BOT'),
                    ]),
                    type=
                    'opencompass.openicl.icl_prompt_template.PromptTemplate'),
                inferencer=dict(
                    max_out_len=8192,
                    type='opencompass.openicl.icl_inferencer.GenInferencer'),
                prompt_template=dict(
                    ice_token='</E>',
                    template=dict(
                        begin='</E>',
                        round=[
                            dict(
                                prompt=
                                "Question:\nThere is a single choice question about high school european history. Answer the question by replying A, B, C or D. {input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer:\nLet's think step by step.\n",
                                role='HUMAN'),
                        ]),
                    type=
                    'opencompass.openicl.icl_prompt_template.PromptTemplate'),
                retriever=dict(
                    type='opencompass.openicl.icl_retriever.ZeroRetriever')),
            name='high_school_european_history',
            path='opencompass/mmlu',
            reader_cfg=dict(
                input_columns=[
                    'input',
                    'A',
                    'B',
                    'C',
                    'D',
                ],
                output_column='target',
                test_range='[99:132]',
                train_split='dev'),
            type='opencompass.datasets.MMLUDataset'),
        dict(
            abbr='lukaemon_mmlu_business_ethics_3',
            eval_cfg=dict(
                evaluator=dict(
                    type='opencompass.openicl.icl_evaluator.AccEvaluator'),
                pred_postprocessor=dict(
                    options='ABCD',
                    type=
                    'opencompass.utils.text_postprocessors.first_option_postprocess'
                )),
            infer_cfg=dict(
                ice_template=dict(
                    template=dict(round=[
                        dict(
                            prompt=
                            'There is a single choice question about business ethics. Answer the question by replying A, B, C or D.\nQ: {input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nA: ',
                            role='HUMAN'),
                        dict(prompt='{target}\n', role='BOT'),
                    ]),
                    type=
                    'opencompass.openicl.icl_prompt_template.PromptTemplate'),
                inferencer=dict(
                    max_out_len=8192,
                    type='opencompass.openicl.icl_inferencer.GenInferencer'),
                prompt_template=dict(
                    ice_token='</E>',
                    template=dict(
                        begin='</E>',
                        round=[
                            dict(
                                prompt=
                                "Question:\nThere is a single choice question about business ethics. Answer the question by replying A, B, C or D. {input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer:\nLet's think step by step.\n",
                                role='HUMAN'),
                        ]),
                    type=
                    'opencompass.openicl.icl_prompt_template.PromptTemplate'),
                retriever=dict(
                    type='opencompass.openicl.icl_retriever.ZeroRetriever')),
            name='business_ethics',
            path='opencompass/mmlu',
            reader_cfg=dict(
                input_columns=[
                    'input',
                    'A',
                    'B',
                    'C',
                    'D',
                ],
                output_column='target',
                test_range='[60:80]',
                train_split='dev'),
            type='opencompass.datasets.MMLUDataset'),
        dict(
            abbr='lukaemon_mmlu_moral_disputes_3',
            eval_cfg=dict(
                evaluator=dict(
                    type='opencompass.openicl.icl_evaluator.AccEvaluator'),
                pred_postprocessor=dict(
                    options='ABCD',
                    type=
                    'opencompass.utils.text_postprocessors.first_option_postprocess'
                )),
            infer_cfg=dict(
                ice_template=dict(
                    template=dict(round=[
                        dict(
                            prompt=
                            'There is a single choice question about moral disputes. Answer the question by replying A, B, C or D.\nQ: {input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nA: ',
                            role='HUMAN'),
                        dict(prompt='{target}\n', role='BOT'),
                    ]),
                    type=
                    'opencompass.openicl.icl_prompt_template.PromptTemplate'),
                inferencer=dict(
                    max_out_len=8192,
                    type='opencompass.openicl.icl_inferencer.GenInferencer'),
                prompt_template=dict(
                    ice_token='</E>',
                    template=dict(
                        begin='</E>',
                        round=[
                            dict(
                                prompt=
                                "Question:\nThere is a single choice question about moral disputes. Answer the question by replying A, B, C or D. {input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer:\nLet's think step by step.\n",
                                role='HUMAN'),
                        ]),
                    type=
                    'opencompass.openicl.icl_prompt_template.PromptTemplate'),
                retriever=dict(
                    type='opencompass.openicl.icl_retriever.ZeroRetriever')),
            name='moral_disputes',
            path='opencompass/mmlu',
            reader_cfg=dict(
                input_columns=[
                    'input',
                    'A',
                    'B',
                    'C',
                    'D',
                ],
                output_column='target',
                test_range='[210:280]',
                train_split='dev'),
            type='opencompass.datasets.MMLUDataset'),
        dict(
            abbr='lukaemon_mmlu_high_school_statistics_3',
            eval_cfg=dict(
                evaluator=dict(
                    type='opencompass.openicl.icl_evaluator.AccEvaluator'),
                pred_postprocessor=dict(
                    options='ABCD',
                    type=
                    'opencompass.utils.text_postprocessors.first_option_postprocess'
                )),
            infer_cfg=dict(
                ice_template=dict(
                    template=dict(round=[
                        dict(
                            prompt=
                            'There is a single choice question about high school statistics. Answer the question by replying A, B, C or D.\nQ: {input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nA: ',
                            role='HUMAN'),
                        dict(prompt='{target}\n', role='BOT'),
                    ]),
                    type=
                    'opencompass.openicl.icl_prompt_template.PromptTemplate'),
                inferencer=dict(
                    max_out_len=8192,
                    type='opencompass.openicl.icl_inferencer.GenInferencer'),
                prompt_template=dict(
                    ice_token='</E>',
                    template=dict(
                        begin='</E>',
                        round=[
                            dict(
                                prompt=
                                "Question:\nThere is a single choice question about high school statistics. Answer the question by replying A, B, C or D. {input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer:\nLet's think step by step.\n",
                                role='HUMAN'),
                        ]),
                    type=
                    'opencompass.openicl.icl_prompt_template.PromptTemplate'),
                retriever=dict(
                    type='opencompass.openicl.icl_retriever.ZeroRetriever')),
            name='high_school_statistics',
            path='opencompass/mmlu',
            reader_cfg=dict(
                input_columns=[
                    'input',
                    'A',
                    'B',
                    'C',
                    'D',
                ],
                output_column='target',
                test_range='[132:176]',
                train_split='dev'),
            type='opencompass.datasets.MMLUDataset'),
        dict(
            abbr='lukaemon_mmlu_miscellaneous_3',
            eval_cfg=dict(
                evaluator=dict(
                    type='opencompass.openicl.icl_evaluator.AccEvaluator'),
                pred_postprocessor=dict(
                    options='ABCD',
                    type=
                    'opencompass.utils.text_postprocessors.first_option_postprocess'
                )),
            infer_cfg=dict(
                ice_template=dict(
                    template=dict(round=[
                        dict(
                            prompt=
                            'There is a single choice question about miscellaneous. Answer the question by replying A, B, C or D.\nQ: {input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nA: ',
                            role='HUMAN'),
                        dict(prompt='{target}\n', role='BOT'),
                    ]),
                    type=
                    'opencompass.openicl.icl_prompt_template.PromptTemplate'),
                inferencer=dict(
                    max_out_len=8192,
                    type='opencompass.openicl.icl_inferencer.GenInferencer'),
                prompt_template=dict(
                    ice_token='</E>',
                    template=dict(
                        begin='</E>',
                        round=[
                            dict(
                                prompt=
                                "Question:\nThere is a single choice question about miscellaneous. Answer the question by replying A, B, C or D. {input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer:\nLet's think step by step.\n",
                                role='HUMAN'),
                        ]),
                    type=
                    'opencompass.openicl.icl_prompt_template.PromptTemplate'),
                retriever=dict(
                    type='opencompass.openicl.icl_retriever.ZeroRetriever')),
            name='miscellaneous',
            path='opencompass/mmlu',
            reader_cfg=dict(
                input_columns=[
                    'input',
                    'A',
                    'B',
                    'C',
                    'D',
                ],
                output_column='target',
                test_range='[471:628]',
                train_split='dev'),
            type='opencompass.datasets.MMLUDataset'),
        dict(
            abbr='lukaemon_mmlu_formal_logic_3',
            eval_cfg=dict(
                evaluator=dict(
                    type='opencompass.openicl.icl_evaluator.AccEvaluator'),
                pred_postprocessor=dict(
                    options='ABCD',
                    type=
                    'opencompass.utils.text_postprocessors.first_option_postprocess'
                )),
            infer_cfg=dict(
                ice_template=dict(
                    template=dict(round=[
                        dict(
                            prompt=
                            'There is a single choice question about formal logic. Answer the question by replying A, B, C or D.\nQ: {input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nA: ',
                            role='HUMAN'),
                        dict(prompt='{target}\n', role='BOT'),
                    ]),
                    type=
                    'opencompass.openicl.icl_prompt_template.PromptTemplate'),
                inferencer=dict(
                    max_out_len=8192,
                    type='opencompass.openicl.icl_inferencer.GenInferencer'),
                prompt_template=dict(
                    ice_token='</E>',
                    template=dict(
                        begin='</E>',
                        round=[
                            dict(
                                prompt=
                                "Question:\nThere is a single choice question about formal logic. Answer the question by replying A, B, C or D. {input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer:\nLet's think step by step.\n",
                                role='HUMAN'),
                        ]),
                    type=
                    'opencompass.openicl.icl_prompt_template.PromptTemplate'),
                retriever=dict(
                    type='opencompass.openicl.icl_retriever.ZeroRetriever')),
            name='formal_logic',
            path='opencompass/mmlu',
            reader_cfg=dict(
                input_columns=[
                    'input',
                    'A',
                    'B',
                    'C',
                    'D',
                ],
                output_column='target',
                test_range='[78:104]',
                train_split='dev'),
            type='opencompass.datasets.MMLUDataset'),
        dict(
            abbr='lukaemon_mmlu_high_school_government_and_politics_3',
            eval_cfg=dict(
                evaluator=dict(
                    type='opencompass.openicl.icl_evaluator.AccEvaluator'),
                pred_postprocessor=dict(
                    options='ABCD',
                    type=
                    'opencompass.utils.text_postprocessors.first_option_postprocess'
                )),
            infer_cfg=dict(
                ice_template=dict(
                    template=dict(round=[
                        dict(
                            prompt=
                            'There is a single choice question about high school government and politics. Answer the question by replying A, B, C or D.\nQ: {input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nA: ',
                            role='HUMAN'),
                        dict(prompt='{target}\n', role='BOT'),
                    ]),
                    type=
                    'opencompass.openicl.icl_prompt_template.PromptTemplate'),
                inferencer=dict(
                    max_out_len=8192,
                    type='opencompass.openicl.icl_inferencer.GenInferencer'),
                prompt_template=dict(
                    ice_token='</E>',
                    template=dict(
                        begin='</E>',
                        round=[
                            dict(
                                prompt=
                                "Question:\nThere is a single choice question about high school government and politics. Answer the question by replying A, B, C or D. {input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer:\nLet's think step by step.\n",
                                role='HUMAN'),
                        ]),
                    type=
                    'opencompass.openicl.icl_prompt_template.PromptTemplate'),
                retriever=dict(
                    type='opencompass.openicl.icl_retriever.ZeroRetriever')),
            name='high_school_government_and_politics',
            path='opencompass/mmlu',
            reader_cfg=dict(
                input_columns=[
                    'input',
                    'A',
                    'B',
                    'C',
                    'D',
                ],
                output_column='target',
                test_range='[117:156]',
                train_split='dev'),
            type='opencompass.datasets.MMLUDataset'),
        dict(
            abbr='lukaemon_mmlu_prehistory_3',
            eval_cfg=dict(
                evaluator=dict(
                    type='opencompass.openicl.icl_evaluator.AccEvaluator'),
                pred_postprocessor=dict(
                    options='ABCD',
                    type=
                    'opencompass.utils.text_postprocessors.first_option_postprocess'
                )),
            infer_cfg=dict(
                ice_template=dict(
                    template=dict(round=[
                        dict(
                            prompt=
                            'There is a single choice question about prehistory. Answer the question by replying A, B, C or D.\nQ: {input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nA: ',
                            role='HUMAN'),
                        dict(prompt='{target}\n', role='BOT'),
                    ]),
                    type=
                    'opencompass.openicl.icl_prompt_template.PromptTemplate'),
                inferencer=dict(
                    max_out_len=8192,
                    type='opencompass.openicl.icl_inferencer.GenInferencer'),
                prompt_template=dict(
                    ice_token='</E>',
                    template=dict(
                        begin='</E>',
                        round=[
                            dict(
                                prompt=
                                "Question:\nThere is a single choice question about prehistory. Answer the question by replying A, B, C or D. {input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer:\nLet's think step by step.\n",
                                role='HUMAN'),
                        ]),
                    type=
                    'opencompass.openicl.icl_prompt_template.PromptTemplate'),
                retriever=dict(
                    type='opencompass.openicl.icl_retriever.ZeroRetriever')),
            name='prehistory',
            path='opencompass/mmlu',
            reader_cfg=dict(
                input_columns=[
                    'input',
                    'A',
                    'B',
                    'C',
                    'D',
                ],
                output_column='target',
                test_range='[195:260]',
                train_split='dev'),
            type='opencompass.datasets.MMLUDataset'),
        dict(
            abbr='lukaemon_mmlu_security_studies_3',
            eval_cfg=dict(
                evaluator=dict(
                    type='opencompass.openicl.icl_evaluator.AccEvaluator'),
                pred_postprocessor=dict(
                    options='ABCD',
                    type=
                    'opencompass.utils.text_postprocessors.first_option_postprocess'
                )),
            infer_cfg=dict(
                ice_template=dict(
                    template=dict(round=[
                        dict(
                            prompt=
                            'There is a single choice question about security studies. Answer the question by replying A, B, C or D.\nQ: {input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nA: ',
                            role='HUMAN'),
                        dict(prompt='{target}\n', role='BOT'),
                    ]),
                    type=
                    'opencompass.openicl.icl_prompt_template.PromptTemplate'),
                inferencer=dict(
                    max_out_len=8192,
                    type='opencompass.openicl.icl_inferencer.GenInferencer'),
                prompt_template=dict(
                    ice_token='</E>',
                    template=dict(
                        begin='</E>',
                        round=[
                            dict(
                                prompt=
                                "Question:\nThere is a single choice question about security studies. Answer the question by replying A, B, C or D. {input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer:\nLet's think step by step.\n",
                                role='HUMAN'),
                        ]),
                    type=
                    'opencompass.openicl.icl_prompt_template.PromptTemplate'),
                retriever=dict(
                    type='opencompass.openicl.icl_retriever.ZeroRetriever')),
            name='security_studies',
            path='opencompass/mmlu',
            reader_cfg=dict(
                input_columns=[
                    'input',
                    'A',
                    'B',
                    'C',
                    'D',
                ],
                output_column='target',
                test_range='[147:196]',
                train_split='dev'),
            type='opencompass.datasets.MMLUDataset'),
        dict(
            abbr='lukaemon_mmlu_high_school_biology_3',
            eval_cfg=dict(
                evaluator=dict(
                    type='opencompass.openicl.icl_evaluator.AccEvaluator'),
                pred_postprocessor=dict(
                    options='ABCD',
                    type=
                    'opencompass.utils.text_postprocessors.first_option_postprocess'
                )),
            infer_cfg=dict(
                ice_template=dict(
                    template=dict(round=[
                        dict(
                            prompt=
                            'There is a single choice question about high school biology. Answer the question by replying A, B, C or D.\nQ: {input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nA: ',
                            role='HUMAN'),
                        dict(prompt='{target}\n', role='BOT'),
                    ]),
                    type=
                    'opencompass.openicl.icl_prompt_template.PromptTemplate'),
                inferencer=dict(
                    max_out_len=8192,
                    type='opencompass.openicl.icl_inferencer.GenInferencer'),
                prompt_template=dict(
                    ice_token='</E>',
                    template=dict(
                        begin='</E>',
                        round=[
                            dict(
                                prompt=
                                "Question:\nThere is a single choice question about high school biology. Answer the question by replying A, B, C or D. {input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer:\nLet's think step by step.\n",
                                role='HUMAN'),
                        ]),
                    type=
                    'opencompass.openicl.icl_prompt_template.PromptTemplate'),
                retriever=dict(
                    type='opencompass.openicl.icl_retriever.ZeroRetriever')),
            name='high_school_biology',
            path='opencompass/mmlu',
            reader_cfg=dict(
                input_columns=[
                    'input',
                    'A',
                    'B',
                    'C',
                    'D',
                ],
                output_column='target',
                test_range='[186:248]',
                train_split='dev'),
            type='opencompass.datasets.MMLUDataset'),
        dict(
            abbr='lukaemon_mmlu_logical_fallacies_3',
            eval_cfg=dict(
                evaluator=dict(
                    type='opencompass.openicl.icl_evaluator.AccEvaluator'),
                pred_postprocessor=dict(
                    options='ABCD',
                    type=
                    'opencompass.utils.text_postprocessors.first_option_postprocess'
                )),
            infer_cfg=dict(
                ice_template=dict(
                    template=dict(round=[
                        dict(
                            prompt=
                            'There is a single choice question about logical fallacies. Answer the question by replying A, B, C or D.\nQ: {input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nA: ',
                            role='HUMAN'),
                        dict(prompt='{target}\n', role='BOT'),
                    ]),
                    type=
                    'opencompass.openicl.icl_prompt_template.PromptTemplate'),
                inferencer=dict(
                    max_out_len=8192,
                    type='opencompass.openicl.icl_inferencer.GenInferencer'),
                prompt_template=dict(
                    ice_token='</E>',
                    template=dict(
                        begin='</E>',
                        round=[
                            dict(
                                prompt=
                                "Question:\nThere is a single choice question about logical fallacies. Answer the question by replying A, B, C or D. {input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer:\nLet's think step by step.\n",
                                role='HUMAN'),
                        ]),
                    type=
                    'opencompass.openicl.icl_prompt_template.PromptTemplate'),
                retriever=dict(
                    type='opencompass.openicl.icl_retriever.ZeroRetriever')),
            name='logical_fallacies',
            path='opencompass/mmlu',
            reader_cfg=dict(
                input_columns=[
                    'input',
                    'A',
                    'B',
                    'C',
                    'D',
                ],
                output_column='target',
                test_range='[99:132]',
                train_split='dev'),
            type='opencompass.datasets.MMLUDataset'),
        dict(
            abbr='lukaemon_mmlu_high_school_world_history_3',
            eval_cfg=dict(
                evaluator=dict(
                    type='opencompass.openicl.icl_evaluator.AccEvaluator'),
                pred_postprocessor=dict(
                    options='ABCD',
                    type=
                    'opencompass.utils.text_postprocessors.first_option_postprocess'
                )),
            infer_cfg=dict(
                ice_template=dict(
                    template=dict(round=[
                        dict(
                            prompt=
                            'There is a single choice question about high school world history. Answer the question by replying A, B, C or D.\nQ: {input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nA: ',
                            role='HUMAN'),
                        dict(prompt='{target}\n', role='BOT'),
                    ]),
                    type=
                    'opencompass.openicl.icl_prompt_template.PromptTemplate'),
                inferencer=dict(
                    max_out_len=8192,
                    type='opencompass.openicl.icl_inferencer.GenInferencer'),
                prompt_template=dict(
                    ice_token='</E>',
                    template=dict(
                        begin='</E>',
                        round=[
                            dict(
                                prompt=
                                "Question:\nThere is a single choice question about high school world history. Answer the question by replying A, B, C or D. {input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer:\nLet's think step by step.\n",
                                role='HUMAN'),
                        ]),
                    type=
                    'opencompass.openicl.icl_prompt_template.PromptTemplate'),
                retriever=dict(
                    type='opencompass.openicl.icl_retriever.ZeroRetriever')),
            name='high_school_world_history',
            path='opencompass/mmlu',
            reader_cfg=dict(
                input_columns=[
                    'input',
                    'A',
                    'B',
                    'C',
                    'D',
                ],
                output_column='target',
                test_range='[144:192]',
                train_split='dev'),
            type='opencompass.datasets.MMLUDataset'),
        dict(
            abbr='lukaemon_mmlu_professional_medicine_3',
            eval_cfg=dict(
                evaluator=dict(
                    type='opencompass.openicl.icl_evaluator.AccEvaluator'),
                pred_postprocessor=dict(
                    options='ABCD',
                    type=
                    'opencompass.utils.text_postprocessors.first_option_postprocess'
                )),
            infer_cfg=dict(
                ice_template=dict(
                    template=dict(round=[
                        dict(
                            prompt=
                            'There is a single choice question about professional medicine. Answer the question by replying A, B, C or D.\nQ: {input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nA: ',
                            role='HUMAN'),
                        dict(prompt='{target}\n', role='BOT'),
                    ]),
                    type=
                    'opencompass.openicl.icl_prompt_template.PromptTemplate'),
                inferencer=dict(
                    max_out_len=8192,
                    type='opencompass.openicl.icl_inferencer.GenInferencer'),
                prompt_template=dict(
                    ice_token='</E>',
                    template=dict(
                        begin='</E>',
                        round=[
                            dict(
                                prompt=
                                "Question:\nThere is a single choice question about professional medicine. Answer the question by replying A, B, C or D. {input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer:\nLet's think step by step.\n",
                                role='HUMAN'),
                        ]),
                    type=
                    'opencompass.openicl.icl_prompt_template.PromptTemplate'),
                retriever=dict(
                    type='opencompass.openicl.icl_retriever.ZeroRetriever')),
            name='professional_medicine',
            path='opencompass/mmlu',
            reader_cfg=dict(
                input_columns=[
                    'input',
                    'A',
                    'B',
                    'C',
                    'D',
                ],
                output_column='target',
                test_range='[165:220]',
                train_split='dev'),
            type='opencompass.datasets.MMLUDataset'),
        dict(
            abbr='lukaemon_mmlu_high_school_mathematics_3',
            eval_cfg=dict(
                evaluator=dict(
                    type='opencompass.openicl.icl_evaluator.AccEvaluator'),
                pred_postprocessor=dict(
                    options='ABCD',
                    type=
                    'opencompass.utils.text_postprocessors.first_option_postprocess'
                )),
            infer_cfg=dict(
                ice_template=dict(
                    template=dict(round=[
                        dict(
                            prompt=
                            'There is a single choice question about high school mathematics. Answer the question by replying A, B, C or D.\nQ: {input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nA: ',
                            role='HUMAN'),
                        dict(prompt='{target}\n', role='BOT'),
                    ]),
                    type=
                    'opencompass.openicl.icl_prompt_template.PromptTemplate'),
                inferencer=dict(
                    max_out_len=8192,
                    type='opencompass.openicl.icl_inferencer.GenInferencer'),
                prompt_template=dict(
                    ice_token='</E>',
                    template=dict(
                        begin='</E>',
                        round=[
                            dict(
                                prompt=
                                "Question:\nThere is a single choice question about high school mathematics. Answer the question by replying A, B, C or D. {input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer:\nLet's think step by step.\n",
                                role='HUMAN'),
                        ]),
                    type=
                    'opencompass.openicl.icl_prompt_template.PromptTemplate'),
                retriever=dict(
                    type='opencompass.openicl.icl_retriever.ZeroRetriever')),
            name='high_school_mathematics',
            path='opencompass/mmlu',
            reader_cfg=dict(
                input_columns=[
                    'input',
                    'A',
                    'B',
                    'C',
                    'D',
                ],
                output_column='target',
                test_range='[162:216]',
                train_split='dev'),
            type='opencompass.datasets.MMLUDataset'),
        dict(
            abbr='lukaemon_mmlu_college_medicine_3',
            eval_cfg=dict(
                evaluator=dict(
                    type='opencompass.openicl.icl_evaluator.AccEvaluator'),
                pred_postprocessor=dict(
                    options='ABCD',
                    type=
                    'opencompass.utils.text_postprocessors.first_option_postprocess'
                )),
            infer_cfg=dict(
                ice_template=dict(
                    template=dict(round=[
                        dict(
                            prompt=
                            'There is a single choice question about college medicine. Answer the question by replying A, B, C or D.\nQ: {input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nA: ',
                            role='HUMAN'),
                        dict(prompt='{target}\n', role='BOT'),
                    ]),
                    type=
                    'opencompass.openicl.icl_prompt_template.PromptTemplate'),
                inferencer=dict(
                    max_out_len=8192,
                    type='opencompass.openicl.icl_inferencer.GenInferencer'),
                prompt_template=dict(
                    ice_token='</E>',
                    template=dict(
                        begin='</E>',
                        round=[
                            dict(
                                prompt=
                                "Question:\nThere is a single choice question about college medicine. Answer the question by replying A, B, C or D. {input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer:\nLet's think step by step.\n",
                                role='HUMAN'),
                        ]),
                    type=
                    'opencompass.openicl.icl_prompt_template.PromptTemplate'),
                retriever=dict(
                    type='opencompass.openicl.icl_retriever.ZeroRetriever')),
            name='college_medicine',
            path='opencompass/mmlu',
            reader_cfg=dict(
                input_columns=[
                    'input',
                    'A',
                    'B',
                    'C',
                    'D',
                ],
                output_column='target',
                test_range='[105:140]',
                train_split='dev'),
            type='opencompass.datasets.MMLUDataset'),
        dict(
            abbr='lukaemon_mmlu_high_school_us_history_3',
            eval_cfg=dict(
                evaluator=dict(
                    type='opencompass.openicl.icl_evaluator.AccEvaluator'),
                pred_postprocessor=dict(
                    options='ABCD',
                    type=
                    'opencompass.utils.text_postprocessors.first_option_postprocess'
                )),
            infer_cfg=dict(
                ice_template=dict(
                    template=dict(round=[
                        dict(
                            prompt=
                            'There is a single choice question about high school us history. Answer the question by replying A, B, C or D.\nQ: {input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nA: ',
                            role='HUMAN'),
                        dict(prompt='{target}\n', role='BOT'),
                    ]),
                    type=
                    'opencompass.openicl.icl_prompt_template.PromptTemplate'),
                inferencer=dict(
                    max_out_len=8192,
                    type='opencompass.openicl.icl_inferencer.GenInferencer'),
                prompt_template=dict(
                    ice_token='</E>',
                    template=dict(
                        begin='</E>',
                        round=[
                            dict(
                                prompt=
                                "Question:\nThere is a single choice question about high school us history. Answer the question by replying A, B, C or D. {input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer:\nLet's think step by step.\n",
                                role='HUMAN'),
                        ]),
                    type=
                    'opencompass.openicl.icl_prompt_template.PromptTemplate'),
                retriever=dict(
                    type='opencompass.openicl.icl_retriever.ZeroRetriever')),
            name='high_school_us_history',
            path='opencompass/mmlu',
            reader_cfg=dict(
                input_columns=[
                    'input',
                    'A',
                    'B',
                    'C',
                    'D',
                ],
                output_column='target',
                test_range='[123:164]',
                train_split='dev'),
            type='opencompass.datasets.MMLUDataset'),
        dict(
            abbr='lukaemon_mmlu_sociology_3',
            eval_cfg=dict(
                evaluator=dict(
                    type='opencompass.openicl.icl_evaluator.AccEvaluator'),
                pred_postprocessor=dict(
                    options='ABCD',
                    type=
                    'opencompass.utils.text_postprocessors.first_option_postprocess'
                )),
            infer_cfg=dict(
                ice_template=dict(
                    template=dict(round=[
                        dict(
                            prompt=
                            'There is a single choice question about sociology. Answer the question by replying A, B, C or D.\nQ: {input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nA: ',
                            role='HUMAN'),
                        dict(prompt='{target}\n', role='BOT'),
                    ]),
                    type=
                    'opencompass.openicl.icl_prompt_template.PromptTemplate'),
                inferencer=dict(
                    max_out_len=8192,
                    type='opencompass.openicl.icl_inferencer.GenInferencer'),
                prompt_template=dict(
                    ice_token='</E>',
                    template=dict(
                        begin='</E>',
                        round=[
                            dict(
                                prompt=
                                "Question:\nThere is a single choice question about sociology. Answer the question by replying A, B, C or D. {input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer:\nLet's think step by step.\n",
                                role='HUMAN'),
                        ]),
                    type=
                    'opencompass.openicl.icl_prompt_template.PromptTemplate'),
                retriever=dict(
                    type='opencompass.openicl.icl_retriever.ZeroRetriever')),
            name='sociology',
            path='opencompass/mmlu',
            reader_cfg=dict(
                input_columns=[
                    'input',
                    'A',
                    'B',
                    'C',
                    'D',
                ],
                output_column='target',
                test_range='[123:164]',
                train_split='dev'),
            type='opencompass.datasets.MMLUDataset'),
        dict(
            abbr='lukaemon_mmlu_econometrics_3',
            eval_cfg=dict(
                evaluator=dict(
                    type='opencompass.openicl.icl_evaluator.AccEvaluator'),
                pred_postprocessor=dict(
                    options='ABCD',
                    type=
                    'opencompass.utils.text_postprocessors.first_option_postprocess'
                )),
            infer_cfg=dict(
                ice_template=dict(
                    template=dict(round=[
                        dict(
                            prompt=
                            'There is a single choice question about econometrics. Answer the question by replying A, B, C or D.\nQ: {input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nA: ',
                            role='HUMAN'),
                        dict(prompt='{target}\n', role='BOT'),
                    ]),
                    type=
                    'opencompass.openicl.icl_prompt_template.PromptTemplate'),
                inferencer=dict(
                    max_out_len=8192,
                    type='opencompass.openicl.icl_inferencer.GenInferencer'),
                prompt_template=dict(
                    ice_token='</E>',
                    template=dict(
                        begin='</E>',
                        round=[
                            dict(
                                prompt=
                                "Question:\nThere is a single choice question about econometrics. Answer the question by replying A, B, C or D. {input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer:\nLet's think step by step.\n",
                                role='HUMAN'),
                        ]),
                    type=
                    'opencompass.openicl.icl_prompt_template.PromptTemplate'),
                retriever=dict(
                    type='opencompass.openicl.icl_retriever.ZeroRetriever')),
            name='econometrics',
            path='opencompass/mmlu',
            reader_cfg=dict(
                input_columns=[
                    'input',
                    'A',
                    'B',
                    'C',
                    'D',
                ],
                output_column='target',
                test_range='[69:92]',
                train_split='dev'),
            type='opencompass.datasets.MMLUDataset'),
        dict(
            abbr='lukaemon_mmlu_high_school_psychology_3',
            eval_cfg=dict(
                evaluator=dict(
                    type='opencompass.openicl.icl_evaluator.AccEvaluator'),
                pred_postprocessor=dict(
                    options='ABCD',
                    type=
                    'opencompass.utils.text_postprocessors.first_option_postprocess'
                )),
            infer_cfg=dict(
                ice_template=dict(
                    template=dict(round=[
                        dict(
                            prompt=
                            'There is a single choice question about high school psychology. Answer the question by replying A, B, C or D.\nQ: {input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nA: ',
                            role='HUMAN'),
                        dict(prompt='{target}\n', role='BOT'),
                    ]),
                    type=
                    'opencompass.openicl.icl_prompt_template.PromptTemplate'),
                inferencer=dict(
                    max_out_len=8192,
                    type='opencompass.openicl.icl_inferencer.GenInferencer'),
                prompt_template=dict(
                    ice_token='</E>',
                    template=dict(
                        begin='</E>',
                        round=[
                            dict(
                                prompt=
                                "Question:\nThere is a single choice question about high school psychology. Answer the question by replying A, B, C or D. {input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer:\nLet's think step by step.\n",
                                role='HUMAN'),
                        ]),
                    type=
                    'opencompass.openicl.icl_prompt_template.PromptTemplate'),
                retriever=dict(
                    type='opencompass.openicl.icl_retriever.ZeroRetriever')),
            name='high_school_psychology',
            path='opencompass/mmlu',
            reader_cfg=dict(
                input_columns=[
                    'input',
                    'A',
                    'B',
                    'C',
                    'D',
                ],
                output_column='target',
                test_range='[327:436]',
                train_split='dev'),
            type='opencompass.datasets.MMLUDataset'),
        dict(
            abbr='lukaemon_mmlu_human_aging_3',
            eval_cfg=dict(
                evaluator=dict(
                    type='opencompass.openicl.icl_evaluator.AccEvaluator'),
                pred_postprocessor=dict(
                    options='ABCD',
                    type=
                    'opencompass.utils.text_postprocessors.first_option_postprocess'
                )),
            infer_cfg=dict(
                ice_template=dict(
                    template=dict(round=[
                        dict(
                            prompt=
                            'There is a single choice question about human aging. Answer the question by replying A, B, C or D.\nQ: {input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nA: ',
                            role='HUMAN'),
                        dict(prompt='{target}\n', role='BOT'),
                    ]),
                    type=
                    'opencompass.openicl.icl_prompt_template.PromptTemplate'),
                inferencer=dict(
                    max_out_len=8192,
                    type='opencompass.openicl.icl_inferencer.GenInferencer'),
                prompt_template=dict(
                    ice_token='</E>',
                    template=dict(
                        begin='</E>',
                        round=[
                            dict(
                                prompt=
                                "Question:\nThere is a single choice question about human aging. Answer the question by replying A, B, C or D. {input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer:\nLet's think step by step.\n",
                                role='HUMAN'),
                        ]),
                    type=
                    'opencompass.openicl.icl_prompt_template.PromptTemplate'),
                retriever=dict(
                    type='opencompass.openicl.icl_retriever.ZeroRetriever')),
            name='human_aging',
            path='opencompass/mmlu',
            reader_cfg=dict(
                input_columns=[
                    'input',
                    'A',
                    'B',
                    'C',
                    'D',
                ],
                output_column='target',
                test_range='[135:180]',
                train_split='dev'),
            type='opencompass.datasets.MMLUDataset'),
        dict(
            abbr='lukaemon_mmlu_us_foreign_policy_3',
            eval_cfg=dict(
                evaluator=dict(
                    type='opencompass.openicl.icl_evaluator.AccEvaluator'),
                pred_postprocessor=dict(
                    options='ABCD',
                    type=
                    'opencompass.utils.text_postprocessors.first_option_postprocess'
                )),
            infer_cfg=dict(
                ice_template=dict(
                    template=dict(round=[
                        dict(
                            prompt=
                            'There is a single choice question about us foreign policy. Answer the question by replying A, B, C or D.\nQ: {input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nA: ',
                            role='HUMAN'),
                        dict(prompt='{target}\n', role='BOT'),
                    ]),
                    type=
                    'opencompass.openicl.icl_prompt_template.PromptTemplate'),
                inferencer=dict(
                    max_out_len=8192,
                    type='opencompass.openicl.icl_inferencer.GenInferencer'),
                prompt_template=dict(
                    ice_token='</E>',
                    template=dict(
                        begin='</E>',
                        round=[
                            dict(
                                prompt=
                                "Question:\nThere is a single choice question about us foreign policy. Answer the question by replying A, B, C or D. {input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer:\nLet's think step by step.\n",
                                role='HUMAN'),
                        ]),
                    type=
                    'opencompass.openicl.icl_prompt_template.PromptTemplate'),
                retriever=dict(
                    type='opencompass.openicl.icl_retriever.ZeroRetriever')),
            name='us_foreign_policy',
            path='opencompass/mmlu',
            reader_cfg=dict(
                input_columns=[
                    'input',
                    'A',
                    'B',
                    'C',
                    'D',
                ],
                output_column='target',
                test_range='[60:80]',
                train_split='dev'),
            type='opencompass.datasets.MMLUDataset'),
        dict(
            abbr='lukaemon_mmlu_conceptual_physics_3',
            eval_cfg=dict(
                evaluator=dict(
                    type='opencompass.openicl.icl_evaluator.AccEvaluator'),
                pred_postprocessor=dict(
                    options='ABCD',
                    type=
                    'opencompass.utils.text_postprocessors.first_option_postprocess'
                )),
            infer_cfg=dict(
                ice_template=dict(
                    template=dict(round=[
                        dict(
                            prompt=
                            'There is a single choice question about conceptual physics. Answer the question by replying A, B, C or D.\nQ: {input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nA: ',
                            role='HUMAN'),
                        dict(prompt='{target}\n', role='BOT'),
                    ]),
                    type=
                    'opencompass.openicl.icl_prompt_template.PromptTemplate'),
                inferencer=dict(
                    max_out_len=8192,
                    type='opencompass.openicl.icl_inferencer.GenInferencer'),
                prompt_template=dict(
                    ice_token='</E>',
                    template=dict(
                        begin='</E>',
                        round=[
                            dict(
                                prompt=
                                "Question:\nThere is a single choice question about conceptual physics. Answer the question by replying A, B, C or D. {input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer:\nLet's think step by step.\n",
                                role='HUMAN'),
                        ]),
                    type=
                    'opencompass.openicl.icl_prompt_template.PromptTemplate'),
                retriever=dict(
                    type='opencompass.openicl.icl_retriever.ZeroRetriever')),
            name='conceptual_physics',
            path='opencompass/mmlu',
            reader_cfg=dict(
                input_columns=[
                    'input',
                    'A',
                    'B',
                    'C',
                    'D',
                ],
                output_column='target',
                test_range='[141:188]',
                train_split='dev'),
            type='opencompass.datasets.MMLUDataset'),
    ],
]
models = [
    dict(
        abbr='huggingface_hf-vllm',
        batch_size=8,
        generation_kwargs=dict(stop_token_ids=None),
        max_out_len=8192,
        max_seq_len=None,
        model_kwargs=dict(max_model_len=None, tensor_parallel_size=1),
        path=
        '/cfs2/hadoop-aipnlp/zengweihao02/checkpoints/verl-grpo-deepseek-math-base-rollout-1024-256mini-remove-reward-tem1.0-fix_qwen_remove_gsm8k_level1_deepseek-math-7b-base/global_step_100/actor/huggingface',
        run_cfg=dict(num_gpus=1),
        type='opencompass.models.vllm.VLLM'),
]
work_dir = '/cfs2/hadoop-aipnlp/zengweihao02/checkpoints/verl-grpo-deepseek-math-base-rollout-1024-256mini-remove-reward-tem1.0-fix_qwen_remove_gsm8k_level1_deepseek-math-7b-base/global_step_100/actor/huggingface/mmlu_abel/qwen_base/20250317_133825'
